# Configuration or a Classifier-Free based DDPM.
model:
  # The number of input channels to the model
  input_channels: 1
  # The number of output channels to the model
  output_channels: 1
  # The spatial size of the input to the model
  input_spatial_size: 32
  # The number of noise scales
  num_scales: 1000
  # The number of features/channels at the start of
  # the network.
  num_features: 128
  # Resnet block channel multipliers.
  channel_multipliers: [1, 2, 2, 2]
  # The number of resnet blocks per resolution.
  num_resnet_blocks: 2
  # The resolution to apply attention layers.
  attention_resolutions: [16]
  # The number of attention heads to use
  num_attention_heads_downsample: 4
  num_attention_heads_upsample: 4
  # Use scale/shift of the GroupNorm in the timestep embedding.
  # This is also called Adaptive Group Normalization.
  use_scale_shift_norm: True
  # Perform resampling using convolutions.
  resamp_with_conv: False
  # BigGAN style resnet block to perform up/down sampling.
  resblock_updown: False
  # The type of resnet block to use
  resnet_block_type: 'biggan'
  # Dropout scale
  dropout: 0.1
  # Is this a v or epsilon-param model?
  is_v_param: False
  # True if this is a class conditional model
  is_class_conditional: False
  # Classifier-free guidance scale, where the value is >= 1.0
  classifier_free_guidance: 4.0
  # Unconditional guidance probability
  unconditional_guidance_probability: 0.2
  # The number of heads in the attention layers
  attention_heads: 1
  # The number of channels in the attention layers
  attention_channels: 64
  # The size of the text context dimension, for text conditioning
  # signals.
  text_context_size: 128
  # The vocabulary size of the text encoder. The total
  # size of the vocabulary is much larger, but we have a much
  # smaller dictionary of tokens that doesn't use the whole vocabulary.
  text_vocabulary_size: 50257
  # Transformer for conditioning on the text context
  context_transformer:
    width: 128
    num_layers: 6
    num_heads: 64
    final_layer_norm: True
    padding: False

text_encoder:
  # The total vocabulary size
  vocabulary_size: 50257

data:
  # Spatial width/height of the data input to the model.
  image_size: 32
  # Number of channels in the input data
  num_channels: 1
  # The number of classes in the dataset
  num_classes: 10

