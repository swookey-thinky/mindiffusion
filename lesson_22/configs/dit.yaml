# Configuration file for DDPM with a transformer backbone, from the paper
# "Scalable Diffusion Models with Transformers" (https://arxiv.org/abs/2212.09748)
diffusion:
  # Sampling section determines the size of the sampled output
  # from the model, and defines the sampling method used
  sampling:
    target: image_diffusion.sampling.AncestralSampler
    params:
      output_channels: 1
      output_spatial_size: 32
  # The noise scheduler to use with the forward diffusion process.
  noise_scheduler:
    # The number of noise scales
    num_scales: 1000
    # The schedule type
    schedule: "linear"
    # Loss type to use for noise prediction.
    loss_type: "l2"
    sampler:
      target: image_diffusion.importance_sampling.UniformSampler
      params:
        num_timesteps: 1000
  # A preprocessor to use with the context before sending to the score network.
  context_preprocessing:
      # No context to preprocess for this model
      - target: image_diffusion.conditioning.IgnoreContextAdapter
        params: {}
  # A preprocessor for input to the model.
  input_preprocessing:
    target: image_diffusion.conditioning.IgnoreInputPreprocessor
    params: {}
  # Setting for classifier free guidance.
  classifier_free_guidance:
    # Classifier-free guidance scale, where the value is >= 1.0
    classifier_free_guidance: 1.0
    # Unconditional guidance probability
    unconditional_guidance_probability: 0.2
    # The context signals to apply guidance to.
    signals: ["classes"]
    # For classifier free guidance, we need the ability to create an unconditional
    # context given the conditional context. This unconditional context needs
    # to be applied in both training and sampling, and will return a new
    # context dictionary given the original context dictionary.
    unconditional_context:
      target: image_diffusion.conditioning.UnconditionalClassesAdapter
      params:
        num_classes: 10
  dynamic_thresholding:
    enable: True
    p: 0.99
    c: 1.7
  # Defines the score network for predicting the noise parameter
  score_network:
    target: image_diffusion.score_networks.transformer.DiT
    params:
      # The number of input channels to the model.
      input_channels: 1
      # The number of output channels to the model.
      output_channels: 1
      # The spatial size of the input to the model.
      input_spatial_size: 32
      # Spatial size of each image patch
      patch_size: 8
      # Hidden size of the transformer
      hidden_size: 384
      # Transformer depth (number of transformer blocks)
      depth: 12
      # Number of attention heads in each transformer block
      num_heads: 6
      # Multiplier for internal dimensions of MLP in each transformer block,
      # mlp_ratio is a multiplier on top of hidden_size above.
      mlp_ratio: 4.0
      # Does the model include a learned sigma or a fixed sigma.
      is_learned_sigma: False
      # True if this is a class conditional model
      is_class_conditional: True
      # Dropout scale
      dropout: 0.1
      # The number of classes for a class conditional model.
      # Only used if is_class_conditional=True.
      num_classes: 10
      # Additional conditioning signals for the model. The projections
      # defined here will be applied before running through the rest of the
      # score network.
      conditioning:
        # The signals (keys in the dictionary) that are available in the conditioning
        # context.
        signals: ["timestep", "classes"]
        projections:
          # A projection to apply to the integer timesteps.
          timestep:
            # Defines a projection incorporating the sinusoidal position embedding.
            # Output size is (B, C, num_features * time_embedding_mult)
            target: image_diffusion.layers.embedding.DiTTimestepEmbedding
            params:
              hidden_size: 384
              frequency_embedding_size: 256
          classes:
            # Defines a projection incorporating the sinusoidal position embedding.
            # Output size is (B, C, num_features * time_embedding_mult)
            target: image_diffusion.layers.embedding.DiTLabelEmbedding
            params:
              hidden_size: 384
              num_classes: 10
        # The context transformer to use at the top of the score network. This transforms
        # the context with a shared set of parameters.
        context_transformer_head:
          # Combines the timestep and class embedding signals into a single embedding
          - target: image_diffusion.layers.embedding.DiTCombineEmbeddngs
            params:
              text_embedding_dim: 512
              time_embedding_dim: 512
              attention_pooling_heads: 1

        # The context transformer to use at each attention layer. This transforms
        # the context with a different set of parameters at each attention layer.
        context_transformer_layer:
          target: torch.nn.Identity
          params: {}
# Describes the dataset used in training.
data:
  # Spatial width/height of the data input to the model.
  image_size: 32
  # Number of channels in the input data
  num_channels: 1
  # The number of classes in the dataset
  num_classes: 10
# Optional optimizer specification
optimizer:
  target: torch.optim.Adam
  params:
    lr: .0002
    betas: [0.9, 0.99]
