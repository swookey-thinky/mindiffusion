# Flux based rectified flow model.
diffusion:
  parameterization: "rectified_flow"

  # Sampling section determines the size of the sampled output
  # from the model, and defines the sampling method used
  sampling:
    output_channels: 1
    output_spatial_size: 32
    target: xdiffusion.samplers.rectified_flow.AncestralSampler
    params: {}

  # The noise scheduler to use with the forward diffusion process.
  noise_scheduler:
    target: xdiffusion.scheduler.DiscreteRectifiedFlowNoiseScheduler
    params:
      # The number of noise scales
      steps: 1000
      # The maximum time
      max_time: 1.0
  sde:
    target: xdiffusion.sde.rectified_flow.RectifiedFlow
    params:
      N: 1000
      T: 1.0
  # A preprocessor to use with the context before sending to the score network.
  context_preprocessing:
      # The Prompts Preprocessor converts the list of text prompts in the context
      # into a batch of text embeddings.
    - target: xdiffusion.context.IgnoreContextAdapter
      params: {}

  # A preprocessor for input to the model.
  input_preprocessing:
    target: xdiffusion.context.IgnoreInputPreprocessor
    params: {}

  # Setting for classifier free guidance.
  classifier_free_guidance:
    # Classifier-free guidance scale, where the value is >= 1.0
    classifier_free_guidance: 1.0
    # Unconditional guidance probability
    unconditional_guidance_probability: 0.2
    # The context signals to apply guidance to.
    signals: ["text_embeddings"]
    # For classifier free guidance, we need the ability to create an unconditional
    # context given the conditional context. This unconditional context needs
    # to be applied in both training and sampling, and will return a new
    # context dictionary given the original context dictionary.
    unconditional_context:
      target: xdiffusion.context.UnconditionalEmbeddingAdapter
      params:
        embedding_shape: [300, 2304]

  # Defines the score network for predicting the noise parameter
  score_network:
    target: xdiffusion.score_networks.sana.SanaScoreNetwork
    params:
      input_spatial_size: 32
      patch_size: 8
      in_channels: 1
      input_channels: 1
      out_channels: 1
      caption_channels: 2304

      # Yields an inner dimension of 32*36 = 1152
      attention_head_dim: 32
      num_attention_heads: 36

      # The cross attention heads total dimension must
      # match the self attention: 16 * 72 = 1152 = 32 * 36
      num_cross_attention_heads: 16
      cross_attention_head_dim: 72
      cross_attention_dim: 1152

      dropout: 0.0
      mlp_ratio: 2.5
      num_layers: 12

      # Required settings
      is_learned_sigma: False
      is_class_conditional: False

      # Additional conditioning signals for the model. The projections
      # defined here will be applied before running through the rest of the
      # score network.
      conditioning:
        # The signals (keys in the dictionary) that are available in the conditioning
        # context.
        signals: []
        projections: {}
        # The context transformer to use at the top of the score network. This transforms
        # the context with a shared set of parameters.
        context_transformer_head:
          # Timestep -> timestep embedding
          - target: torch.nn.Identity
            params: {}

# Describes the dataset used in training.
data:
  # Spatial width/height of the data input to the model.
  image_size: 32
  # Number of channels in the input data
  num_channels: 1
  # The number of classes in the dataset
  num_classes: 10

# Separate sampling section, handled outside of the model training/inference.
# This can be used to configure different caption encoders, specifically if they
# are too large to be handled in the model itself.
sampling:
  # The Prompts Preprocessor converts the list of text prompts in the context
  # into a batch of text embeddings.
  prompt_encoder:
    target: xdiffusion.layers.embedding.SanaPromptToTextEmbedding
    params:
      text_encoder_model_name: "google/gemma-2-2b-it"
      max_length: 300
      input_key: "text_prompts"
      output_key: "text_embeddings"
      use_bfloat16: False

      # TODO: Find a way to enable CPU offloading here. We are trying to use
      #       accelerate.cpu_offload() to support full offloading.
      enable_cpu_offload: False

      # Run the text encoder on CPU. Theoretically we should be able to use
      # CPU offloading with this model, but there are some errors related
      # to meta devices when trying to offload it.
      device_map: "cpu"

# Describes parameters of the training process.
training:
  # Batch size to use for training
  batch_size: 16
  # The number of steps to perform gradient accumulation
  gradient_accumulation_steps: 4
  # Mixed precision training settings
  mixed_precision: "bf16"
  # The dataset we are training on
  dataset: "image/mnist_embedded_gemma_2"
