# Configuration for Latent Diffusion Model.
model:
  # The number of noise scales
  num_scales: 1000
  # The number of features/channels at the start of
  # the network.
  num_features: 128
  # Resnet block channel multipliers.
  channel_multipliers: [1, 2, 2]
  # The number of resnet blocks per resolution.
  num_resnet_blocks: 2
  # The resolution to apply attention layers.
  attention_resolutions: [4]
  # The number of attention heads to use
  num_attention_heads_downsample: 4
  num_attention_heads_upsample: 4
  # Use scale/shift of the GroupNorm in the timestep embedding.
  # This is called Adaptive Group Normalization in the paper.
  use_scale_shift_norm: True
  # Perform resampling using convolutions.
  resamp_with_conv: False
  # BigGAN style resnet block to perform up/down sampling.
  resblock_updown: False
  # The type of resnet block to use
  resnet_block_type: 'ddpm'
  # Dropout scale
  dropout: 0.1
  # Is this a v or epsilon-param model?
  is_v_param: False
  # True if this is a class conditional model
  is_class_conditional: False
  # The size of the latent dimension
  latent_size: 8
  # The number of channels in the latent
  latent_channels: 4
  # The size of the context dimension, for context conditioning
  # signals.
  context_size: 768
  # The number of heads in the attention layers
  attention_heads: 1
  # The number of channels in the attention layers
  attention_channels: 64
  # Configuration of the VAE used in the model
  vae:
    target: autoencoders.kl.AutoencoderKL
    params:
      embed_dim: 4
      loss_config:
        target: autoencoders.losses.LPIPSWithDiscriminator
        params:
          disc_start: 1000
          kl_weight: 0.000001
          disc_weight: 0.5
          disc_in_channels: 1

      encoder_decoder_config:
        double_z: True
        z_channels: 4
        resolution: 32
        in_channels: 1
        out_ch: 1
        ch: 128
        ch_mult: [1,1,2]  # num_down = len(ch_mult)-1
        num_res_blocks: 2
        attn_resolutions: [16,8]
        dropout: 0.0


data:
  # Spatial width/height of the data. For MNIST, we resize
  # to 32 to make the math easier.
  image_size: 32
  # Number of channels in the input data
  num_channels: 1
  # The number of classes in the dataset
  num_classes: 10
